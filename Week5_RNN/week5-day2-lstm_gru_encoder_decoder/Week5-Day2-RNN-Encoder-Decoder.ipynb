{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN - Encoder-Decoder Model\n",
    "\n",
    "## Toy-Project: Simple Calculator using RNN\n",
    "\n",
    "- input:\n",
    "\n",
    "        '1','5','5', '+', '3','3','9'\n",
    "\n",
    "\n",
    "- output:\n",
    "\n",
    "        '4', '9', '3', ' ', ' '\n",
    "  \n",
    "\n",
    "- 입력은 숫자 두 개에 대한 연산식\n",
    "\n",
    "- 출력은 연산 결과 문자열\n",
    "\n",
    "- 입력 숫자는 각각 1~3 자리로서, 전체 수식은 연산자 포함해서 최대 7자\n",
    "\n",
    "- 출력 숫자는 1~4 자리인데, END 표시로 사용하는 `' '` 문자 포함해서 최대 5자\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN, Encoder/Decoder\n",
    "\n",
    "<img  src=\"20160120182108205.jpg\" style=\"width:55.0rem\"/>\n",
    "\n",
    "<div style=\"text-align:center\">이미지 출처: http://www.voidcn.com/article/p-virvaiso-zw.html</div>\n",
    "\n",
    "\n",
    "<img src=\"68747.jpg\" style=\"width:55.0rem\">\n",
    "\n",
    "<div style=\"text-align:center\">이미지 출처: https://github.com/guillaume-chevalier/seq2seq-signal-prediction</div>\n",
    "\n",
    "\n",
    "### Encoder/Decoder - Inference\n",
    "\n",
    "- 수식이 encoder 쪽에 들어오면, encoder 는 _**계산**_ 을 해서 그 결과를 state 로 기억\n",
    "- decoder 쪽에 START 문자 (`'='`) 가 입력되고 decoder 가 시작되면, encoder 의 state 를 받아 초기 상태로 사용하면서 state 가 표현하려는 결과를 다시 숫자열로 출력\n",
    "\n",
    "### Encoder/Decoder - Training\n",
    "\n",
    "- 입력할 수식, 출력할 숫자열을 훈련데이터로 제시\n",
    "- 출력할 숫자열은 sequence-to-sequence 방식으로 훈련\n",
    "  - decoder 입력으로는 `'='` 문자를 앞에 붙인 출력 숫자열 제시\n",
    "  - decoder 출력으로는 `' '` 문자 (END) 를 뒤에 붙인 수식을 제시\n",
    "  - decoder 입력-출력 pair 를 하나씩 보면, 앞 자리의 숫자를 입력하면 현재 자리의 숫자를 출력하는 RNN을 학습하는 것이 됨\n",
    "  \n",
    "  \n",
    "```\n",
    "                                                 decoder outputs\n",
    "\n",
    "                                                5   7   9   \n",
    "        +---+---+---+---+---+---+---+         +---+---+---+---+\n",
    "encoder |   |   |   |   |   |   |   +---------+   |   |   |   | decoder\n",
    "        +---+---+---+---+---+---+---+         +---+---+---+---+\n",
    "\n",
    "          1   2   3   +   4   5   6             =   5   7   9\n",
    "\n",
    "              encoder inputs                     decoder inputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:28.712517Z",
     "start_time": "2017-10-11T01:45:28.480479Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr logdir2\n",
    "!mkdir -p logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.370534Z",
     "start_time": "2017-10-11T01:45:28.713749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@media print {\n",
       "  a[href]:after {\n",
       "    content: none !important;\n",
       "  }\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext do_not_print_href\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set - symbols & symbol map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력/출력 문자는 0~9 까지의 숫자, 연산자 `'+'`, `' '` (END), `'='` (START) 포함하여 13 종류\n",
    "\n",
    "- 사용가능한 연산자는 `'+'`\n",
    "\n",
    "- 문자(symbol) 와 해당 문자의 인덱스 넘버 사이의 변환을 위한 배열/사전 준비\n",
    "\n",
    "  - `symbols[]`    : 인덱스에서 문자로\n",
    "  - `symbol_map[]` : 문자에서 인덱스로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.380376Z",
     "start_time": "2017-10-11T01:45:29.374030Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbols        = [' ', '0', '1', '2', '3', '4', '5',\n",
    "                  '6', '7', '8', '9', '+', '=']\n",
    "operators      = ['+']\n",
    "\n",
    "symbol_map     = {s: i \\\n",
    "                  for i,s in enumerate(symbols)}\n",
    "input_units    = output_units    = len(symbol_map)\n",
    "hidden_units   = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.393602Z",
     "start_time": "2017-10-11T01:45:29.381594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol_map = {' ': 0, '+': 11, '1': 2, '0': 1, '3': 4, '2': 3, '5': 6, '4': 5, '7': 8, '6': 7, '9': 10, '8': 9, '=': 12}\n"
     ]
    }
   ],
   "source": [
    "print('symbol_map =',symbol_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set - Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.402041Z",
     "start_time": "2017-10-11T01:45:29.396723Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_random_data():\n",
    "    t1        = str(np.random.randint(1000))\n",
    "    op        = np.random.choice(operators)\n",
    "    t2        = str(np.random.randint(1000))\n",
    "    \n",
    "    expr      = t1 + op + t2\n",
    "    ans       = '='+str(eval(expr))+' '\n",
    "    \n",
    "    return expr, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.414660Z",
     "start_time": "2017-10-11T01:45:29.403871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['3', '0', '5', '+', '5', '2', '7'], ['=', '8', '3', '2', ' '])\n",
      "(['3', '3', '5', '+', '7', '5', '9'], ['=', '1', '0', '9', '4', ' '])\n",
      "(['7', '5', '6', '+', '5', '6', '1'], ['=', '1', '3', '1', '7', ' '])\n",
      "(['3', '3', '9', '+', '7', '6'], ['=', '4', '1', '5', ' '])\n",
      "(['5', '9', '0', '+', '2', '9', '9'], ['=', '8', '8', '9', ' '])\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    expr, ans = make_random_data()\n",
    "    print(([c for c in expr], [c for c in ans]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set - one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.425767Z",
     "start_time": "2017-10-11T01:45:29.416048Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot(n):\n",
    "    \"\"\"\n",
    "    3 ==> [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \"\"\"\n",
    "    res = np.zeros(13, dtype=np.float32)\n",
    "    res[n] = 1.0\n",
    "    return res\n",
    "\n",
    "def arg_max(v):\n",
    "    \"\"\"\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] ==> 3\n",
    "    \"\"\"\n",
    "    return np.argmax(v, axis=-1)\n",
    "\n",
    "# test\n",
    "assert 7 == arg_max(one_hot(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.435656Z",
     "start_time": "2017-10-11T01:45:29.428663Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_seq_len = 7\n",
    "decoder_max_seq_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.448895Z",
     "start_time": "2017-10-11T01:45:29.436987Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_onehot(str, max_seq_len):\n",
    "    buf           = np.zeros([max_seq_len,input_units])\n",
    "    buf          += \\\n",
    "      one_hot(symbol_map[' ']).reshape([1,-1]) # <<<===\n",
    "    seq_len       = len(str)\n",
    "    buf[:seq_len] = [one_hot(symbol_map[c]) for c in str]\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.461386Z",
     "start_time": "2017-10-11T01:45:29.450114Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_to_str(data, data_len):\n",
    "    return ''.join([symbols[v] \\\n",
    "                    for v in arg_max(data)][:data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.470585Z",
     "start_time": "2017-10-11T01:45:29.465736Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_data(expr, ans):\n",
    "    e_seq_len         = len(expr)\n",
    "    e_in              = str_to_onehot(expr,\n",
    "                                      encoder_max_seq_len)\n",
    "    d_seq_len         = len(ans) - 1\n",
    "    d_in              = str_to_onehot(ans[:-1],\n",
    "                                      decoder_max_seq_len)\n",
    "    d_out             = str_to_onehot(ans[1:],\n",
    "                                      decoder_max_seq_len)\n",
    "    return e_seq_len, e_in, d_seq_len, d_in, d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.479701Z",
     "start_time": "2017-10-11T01:45:29.473777Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_data(e_len, e_in, d_len, d_in, d_out):\n",
    "    return  e_len, \\\n",
    "            onehot_to_str(e_in, e_len), \\\n",
    "            d_len, \\\n",
    "            onehot_to_str(d_in, d_len), \\\n",
    "            onehot_to_str(d_out, d_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.489420Z",
     "start_time": "2017-10-11T01:45:29.481005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, '553+401', 4, '=954', '954 ')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_data(*encode_data(*make_random_data()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set: create data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.501075Z",
     "start_time": "2017-10-11T01:45:29.491750Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.512670Z",
     "start_time": "2017-10-11T01:45:29.502266Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_data = 60000\n",
    "test_num_data  = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.319507Z",
     "start_time": "2017-10-11T01:45:29.513932Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# common data format\n",
    "# e_len, e_in, d_len, d_in, d_out\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.encoder_seq_len  = []\n",
    "        self.encoder_in_data  = []\n",
    "        self.decoder_seq_len  = []\n",
    "        self.decoder_in_data  = []\n",
    "        self.decoder_out_data = []\n",
    "        \n",
    "    def append(self, t):\n",
    "        self.encoder_seq_len.append(t[0])\n",
    "        self.encoder_in_data.append(t[1])\n",
    "        self.decoder_seq_len.append(t[2])\n",
    "        self.decoder_in_data.append(t[3])\n",
    "        self.decoder_out_data.append(t[4])\n",
    "        \n",
    "    def next_batch(self,batch_size=BATCH_SIZE):\n",
    "        data_len = len(self.encoder_seq_len)\n",
    "        batch_pointer = 0\n",
    "        while batch_pointer + batch_size <= data_len:\n",
    "            ss   = np.random.randint(\n",
    "                data_len - batch_size - 1)\n",
    "            yield \\\n",
    "                self.encoder_seq_len[ss:ss+batch_size], \\\n",
    "                self.encoder_in_data[ss:ss+batch_size], \\\n",
    "                self.decoder_seq_len[ss:ss+batch_size], \\\n",
    "                self.decoder_in_data[ss:ss+batch_size], \\\n",
    "                self.decoder_out_data[ss:ss+batch_size]\n",
    "            batch_pointer += batch_size\n",
    "\n",
    "\n",
    "np.random.seed(37L)\n",
    "\n",
    "train_data = Dataset()\n",
    "for i in range(train_num_data):\n",
    "    expr, ans     = make_random_data()\n",
    "    train_data.append(encode_data(expr, ans))\n",
    "\n",
    "test_data  = Dataset()\n",
    "for i in range(test_num_data):\n",
    "    expr, ans     = make_random_data()\n",
    "    test_data.append(encode_data(expr, ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set: data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print & verify first training data\n",
    "\n",
    "- `next_batch()` 는 `for` 문장과 함께 쓰일 수 있음.\n",
    "- `next_batch()` 가 `for` 문장과 함께 쓰지지 않는 경우는 다시 next() 를 호출해야 함. (python interator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.327669Z",
     "start_time": "2017-10-11T01:45:33.321357Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, '756+55', 4, '=811', '811 ')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_len,e_in,d_len,d_in,d_out = train_data.next_batch().next()\n",
    "decode_data(e_len[0],e_in[0],d_len[0],d_in[0],d_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.340346Z",
     "start_time": "2017-10-11T01:45:33.331423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, '269+927', 5, '=1196', '1196 ')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_data(e_len[1],e_in[1],d_len[1],d_in[1],d_out[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow - build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.345533Z",
     "start_time": "2017-10-11T01:45:33.343653Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow - placeholders & dynamic batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.385906Z",
     "start_time": "2017-10-11T01:45:33.346950Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs   = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, encoder_max_seq_len, input_units],\n",
    "    name='encoder_inputs')\n",
    "encoder_seqlen   = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=[None],\n",
    "    name='encoder_seqlen')\n",
    "decoder_inputs   = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, decoder_max_seq_len, input_units],\n",
    "    name='decoder_inputs')\n",
    "decoder_targets  = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, decoder_max_seq_len, output_units],\n",
    "    name='decoder_targets')\n",
    "decoder_seqlen   = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=[None],\n",
    "    name='decoder_seqlen')\n",
    "encoder_training = tf.placeholder(\n",
    "    dtype=tf.bool,\n",
    "    shape=None,\n",
    "    name='encoder_training')\n",
    "tf_batch_size = tf.shape(encoder_inputs)[0] # <<== !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.401416Z",
     "start_time": "2017-10-11T01:45:33.387467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN, Encoder/Decoder - 2-Layers, with Dropouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [`tf.cond()`](http://devdocs.io/tensorflow~python/tf/cond)\n",
    "> Return true_fn() if the predicate pred is true else false_fn()\n",
    "\n",
    "```\n",
    "cond(\n",
    "    pred,\n",
    "    true_fn=None,\n",
    "    false_fn=None,\n",
    "    strict=False,\n",
    "    name=None,\n",
    "    fn1=None,\n",
    "    fn2=None\n",
    ")\n",
    "```\n",
    "\n",
    "- `true_fn`, `false_fn` 에는 [lambda expression](https://docs.python.org/2.7/reference/expressions.html#lambda) 이 종종 사용됨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.409312Z",
     "start_time": "2017-10-11T01:45:33.403593Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "keep_prob = tf.cond(encoder_training,\n",
    "                    lambda: tf.constant(1.0-dropout_rate),\n",
    "                    lambda: tf.constant(1.0),\n",
    "                    name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [`tf.contrib.rnn.DropoutWrapper`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/dropoutwrapper)\n",
    "\n",
    "<code>\n",
    "    `__init__`(\n",
    "        <span style=\"color:red\">cell,</span>\n",
    "        input_keep_prob=1.0,\n",
    "        output_keep_prob=1.0,\n",
    "        state_keep_prob=1.0,\n",
    "        <span style=\"color:red\">variational_recurrent=False,</span>\n",
    "        input_size=None,\n",
    "        dtype=None,\n",
    "        seed=None\n",
    "    )\n",
    "</code>\n",
    "\n",
    "\n",
    "- `dropout_prob` 이 아니라 `keep_prob` 를 적어주는 점에 유의\n",
    "\n",
    "- `input_keep_prob`, `output_keep_prob`, `state_keep_prob` 로 구분하여 적용\n",
    "\n",
    "- `variational_recurrent` 플래그 (**_tensorflow_** 1.1 부터 지원)\n",
    "\n",
    "  - [A Theorerically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n",
    "\n",
    "  - RNN의 경우, 훈련데이터에 overfitting 하는 경향이 심한데, 일반적인 dropout 방식을 사용해도 효과가 없더라\n",
    "  \n",
    "  - Bayesian interpretation 으로 dropout 기법에 대해서 분석해 본 결과 RNN 에 적용 가능한 새로운 dropout 기법을 개발\n",
    "\n",
    "\n",
    "- [`tf.contrib.rnn.LayerNormBasicLSTMCell`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/layernormbasiclstmcell) 에는 자체 [_recurrent dropout_](https://arxiv.org/abs/1603.05118) 지원 기능이 있음\n",
    "\n",
    "```\n",
    "    __init__(\n",
    "        num_units,\n",
    "        forget_bias=1.0,\n",
    "        input_size=None,\n",
    "        activation=tf.tanh,\n",
    "        layer_norm=True,\n",
    "        norm_gain=1.0,\n",
    "        norm_shift=0.0,\n",
    "        dropout_keep_prob=1.0,\n",
    "        dropout_prob_seed=None,\n",
    "        reuse=None\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> BasicRNNCell, BasicLSTMCell, GRUCell 모두 state 의 형태가 다르다 </span>\n",
    "\n",
    "#### cell initial state 를 생성하기 위해서는 [`cell.zero_state()`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/RNNCell#zero_state) 메소드 사용\n",
    "\n",
    "<code>\n",
    "    zero_state(\n",
    "        batch_size,\n",
    "        dtype\n",
    "    )\n",
    "</code>\n",
    "\n",
    "- batch_size: int, float, or <span style=\"color:red\">unit Tensor</span> representing the batch size.\n",
    "\n",
    "- dtype: the data type to use for the state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-RNN 과 Decoder-RNN 은 `initial_state` 를 통해서 연결된다\n",
    "\n",
    "- Encoder-RNN\n",
    "<code>\n",
    "    encoder_out, <span style=\"color:red\">encoder_state</span> = tf.nn.dynamic_rnn(...)\n",
    "</code>\n",
    "\n",
    "\n",
    "- DecoderRNN\n",
    "<code>\n",
    "    decoder_out, decoder_state = tf.nn.dynamic_rnn(... <span style=\"color:red\">initial_state=encoder_state</span>)\n",
    "</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.279454Z",
     "start_time": "2017-10-11T01:45:33.411152Z"
    }
   },
   "outputs": [],
   "source": [
    "# encoder RNN\n",
    "\n",
    "def e_cell(input_size):\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LSTMCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LayerNormBasicLSTMCell(\n",
    "#              hidden_units)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        cell,\n",
    "        state_keep_prob = keep_prob,\n",
    "        variational_recurrent = True,\n",
    "        input_size = input_size,\n",
    "        dtype = tf.float32)\n",
    "    return cell\n",
    "\n",
    "with tf.variable_scope('encoder'):\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(\n",
    "        [\n",
    "            e_cell(input_units),\n",
    "            e_cell(hidden_units),\n",
    "            e_cell(hidden_units)\n",
    "        ])\n",
    "    initial_state = cell.zero_state(\n",
    "        batch_size=tf_batch_size,\n",
    "        dtype=tf.float32)\n",
    "    encoder_out, encoder_state = tf.nn.dynamic_rnn(\n",
    "        cell,\n",
    "        encoder_inputs,\n",
    "        sequence_length=encoder_seqlen,\n",
    "        initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.359677Z",
     "start_time": "2017-10-11T01:45:34.280682Z"
    }
   },
   "outputs": [],
   "source": [
    "# decoder RNN\n",
    "def d_cell():\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LSTMCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LayerNormBasicLSTMCell(\n",
    "#              hidden_units)\n",
    "    return cell\n",
    "\n",
    "with tf.variable_scope('decoder'):\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(\n",
    "        [d_cell() for _ in range(3)])\n",
    "    initial_state = encoder_state # <<<==== \n",
    "    decoder_out, decoder_state = tf.nn.dynamic_rnn(\n",
    "        cell,\n",
    "        decoder_inputs,\n",
    "        sequence_length=decoder_seqlen,\n",
    "        initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.365887Z",
     "start_time": "2017-10-11T01:45:34.360977Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 7, 100]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.374602Z",
     "start_time": "2017-10-11T01:45:34.367079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 5, 100]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Network after RNN\n",
    "\n",
    "- 5주 1일차에 사용한 코드는 이렇지만,\n",
    "\n",
    "\n",
    "<div  style=\"width:45.0rem;margin:auto;border:1px solid black;border-radius:3px\">\n",
    "<code>\n",
    "        # 10 개의 output units 로 만들 \n",
    "        #  FCN (fully-connected-network) 구성\n",
    "        # outputs shape will become: [batch_size, 10]\n",
    "        <span style=\"color:red\">outputs    = tf.layers.dense(rnn_output, 10)</span>\n",
    "\n",
    "</code>\n",
    "</div>\n",
    "\n",
    "- 이번에는 `tf.nn.xw_plus_b()` 를 이용해서 만들어 봅니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.395408Z",
     "start_time": "2017-10-11T01:45:34.376754Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_w    = tf.get_variable(\n",
    "                \"output_w\",\n",
    "                [hidden_units, output_units])\n",
    "output_b    = tf.get_variable(\n",
    "                \"output_b\",\n",
    "                [output_units])\n",
    "\n",
    "# xw_plus_b() 는 2D 텐서만 처리할 수 있음\n",
    "decoder_o_  = tf.reshape(decoder_out,\n",
    "                         [-1, hidden_units])\n",
    "outputs_    = tf.nn.xw_plus_b(decoder_o_,\n",
    "                              output_w,\n",
    "                              output_b)\n",
    "# xw_plus_b() 를 위해 변형했던 것 처럼 출력을 다시 원 형태로 원복\n",
    "outputs     = tf.reshape(\n",
    "                outputs_,\n",
    "                [-1, decoder_max_seq_len, output_units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.399472Z",
     "start_time": "2017-10-11T01:45:34.396688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 5, 13]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.486625Z",
     "start_time": "2017-10-11T01:45:34.400676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_config = tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    gpu_options={'allow_growth': True})\n",
    "sess = tf.InteractiveSession(config=tf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.668287Z",
     "start_time": "2017-10-11T01:45:34.487881Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.856848Z",
     "start_time": "2017-10-11T01:45:34.669578Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_len, e_in, d_len, d_in, d_out = \\\n",
    "    train_data.next_batch().next()\n",
    "feed = {\n",
    "    encoder_training: False,\n",
    "    encoder_seqlen: e_len,\n",
    "    encoder_inputs: e_in,\n",
    "    decoder_seqlen: d_len,\n",
    "    decoder_inputs: d_in,\n",
    "    decoder_targets: d_out,\n",
    "}\n",
    "out = sess.run(outputs, feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.863270Z",
     "start_time": "2017-10-11T01:45:34.858235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  6,  7, 11,  6,  6,  0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_max(e_in[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.878447Z",
     "start_time": "2017-10-11T01:45:34.864865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, '756+55', 4, '=811', '811 ')\n",
      "(7, '269+927', 5, '=1196', '1196 ')\n",
      "(7, '208+259', 4, '=467', '467 ')\n",
      "(7, '529+653', 5, '=1182', '1182 ')\n",
      "(7, '928+119', 5, '=1047', '1047 ')\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(decode_data(e_len[i],e_in[i],d_len[i],d_in[i],d_out[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare training target vs output\n",
    "\n",
    "- handling sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.895467Z",
     "start_time": "2017-10-11T01:45:34.879844Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_mask_ = tf.sequence_mask(\n",
    "                decoder_seqlen,\n",
    "                maxlen=decoder_max_seq_len,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "seq_mask     = \\\n",
    "    tf.tile(\n",
    "        tf.reshape(\n",
    "            seq_mask_,\n",
    "            [-1,decoder_max_seq_len,1]),\n",
    "        [1,1,output_units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.918421Z",
     "start_time": "2017-10-11T01:45:34.896864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_seq_mask_,a_seq_mask = sess.run(\n",
    "    [\n",
    "        seq_mask_,\n",
    "        seq_mask,\n",
    "    ],\n",
    "    {decoder_seqlen: [1,2,3,4,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.928262Z",
     "start_time": "2017-10-11T01:45:34.919877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_seq_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.938073Z",
     "start_time": "2017-10-11T01:45:34.929613Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_seq_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.976555Z",
     "start_time": "2017-10-11T01:45:34.939458Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss         = tf.losses.softmax_cross_entropy(\n",
    "                    decoder_targets * seq_mask,\n",
    "                    outputs * seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.446179Z",
     "start_time": "2017-10-11T01:45:34.978409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer    = tf.train.AdamOptimizer( \\\n",
    "                  learning_rate=0.001)\n",
    "optimize     = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.489016Z",
     "start_time": "2017-10-11T01:45:35.447288Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer가 새로 변수를 만들었을 것이므로\n",
    "# 변수 초기화를 다시 해야 함\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.562258Z",
     "start_time": "2017-10-11T01:45:35.490377Z"
    },
    "cell_style": "center",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e_len, e_in, d_len, d_in, d_out = \\\n",
    "    train_data.next_batch().next()\n",
    "feed = {\n",
    "    encoder_training: True,\n",
    "    encoder_seqlen:   e_len,\n",
    "    encoder_inputs:   e_in,\n",
    "    decoder_seqlen:   d_len,\n",
    "    decoder_inputs:   d_in,\n",
    "    decoder_targets:  d_out,\n",
    "}\n",
    "_, out, loss_value = \\\n",
    "    sess.run([optimize, outputs, loss], feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.570554Z",
     "start_time": "2017-10-11T01:45:35.563427Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 5, 13), (200, 5, 13), 2.4797435)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(d_out).shape, out.shape, loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.581928Z",
     "start_time": "2017-10-11T01:45:35.571768Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_equals(a,b,a_len=None,b_len=None):\n",
    "    if a_len is None: a_len = len(a)\n",
    "    if b_len is None: b_len = len(b)\n",
    "    a_nums = np.argmax(a[:a_len],-1)\n",
    "    b_nums = np.argmax(b[:b_len],-1)\n",
    "    return 1.0 * np.all(np.equal(a_nums, b_nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.592312Z",
     "start_time": "2017-10-11T01:45:35.583111Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.619717Z",
     "start_time": "2017-10-11T01:45:35.593609Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, writer):\n",
    "    t_start = time.time()\n",
    "    step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        losses  = []\n",
    "        errs    = []\n",
    "        for e_len, e_in, d_len, d_in, d_out \\\n",
    "                in train_data.next_batch():\n",
    "            feed = {\n",
    "                encoder_training: True,\n",
    "                encoder_seqlen:   e_len,\n",
    "                encoder_inputs:   e_in,\n",
    "                decoder_seqlen:   d_len,\n",
    "                decoder_inputs:   d_in,\n",
    "                decoder_targets:  d_out,\n",
    "            }\n",
    "            _, out, training_loss = \\\n",
    "                sess.run([optimize, outputs, loss], feed)\n",
    "            training_err = 1.0 - \\\n",
    "                np.mean([\n",
    "                    seq_equals(a,b,a_len,b_len)\n",
    "                    for a,b,a_len,b_len in\n",
    "                    zip(d_out,out,d_len,d_len)\n",
    "                ])\n",
    "            losses.append(training_loss)\n",
    "            errs.append(training_err)\n",
    "        test_errs   = []\n",
    "        for e_len, e_in, d_len, d_in, d_out \\\n",
    "                in test_data.next_batch():\n",
    "            feed = {\n",
    "                encoder_training: False,\n",
    "                encoder_seqlen:   e_len,\n",
    "                encoder_inputs:   e_in,\n",
    "                decoder_seqlen:   d_len,\n",
    "                decoder_inputs:   d_in,\n",
    "                decoder_targets:  d_out,\n",
    "            }\n",
    "            out, = sess.run([outputs], feed)\n",
    "            test_err = 1.0 - \\\n",
    "                np.mean([\n",
    "                    seq_equals(a,b,a_len,b_len)\n",
    "                    for a,b,a_len,b_len in\n",
    "                    zip(d_out,out,d_len,d_len)\n",
    "                ])\n",
    "            test_errs.append(test_err)\n",
    "        mean_loss       = np.mean(losses)\n",
    "        mean_err        = np.mean(errs)\n",
    "        mean_test_err   = np.mean(test_errs)\n",
    "        summary = tf.Summary(\n",
    "            value=[\n",
    "                tf.Summary.Value(\n",
    "                    tag='loss',\n",
    "                    simple_value=mean_loss),\n",
    "                tf.Summary.Value(\n",
    "                    tag='train_err',\n",
    "                    simple_value=mean_err),\n",
    "                tf.Summary.Value(\n",
    "                    tag='test_err',\n",
    "                    simple_value=mean_test_err),\n",
    "            ])\n",
    "        writer.add_summary(summary,epoch+1)\n",
    "        if 0 == (epoch+1) % 10:\n",
    "            t_elapsed = time.time() - t_start\n",
    "            print(('epoch: {:d}, loss: {:.5f}, ' +\n",
    "                   'err: {:.5f}, test_err: {:.5f}, ' +\n",
    "                   'elapsed: {:.2f}').format(\n",
    "                epoch+1,\n",
    "                mean_loss,\n",
    "                mean_err,\n",
    "                mean_test_err,\n",
    "                t_elapsed))\n",
    "            t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.537Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\n",
    "            'logdir2/encoder_decoder',\n",
    "            tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.539Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.82968, err: 0.95273, test_err: 0.89870, elapsed: 31.71\n",
      "epoch: 20, loss: 0.51765, err: 0.73782, test_err: 0.47990, elapsed: 31.76\n",
      "epoch: 30, loss: 0.42438, err: 0.64033, test_err: 0.23110, elapsed: 31.94\n",
      "epoch: 40, loss: 0.36916, err: 0.57262, test_err: 0.24230, elapsed: 31.89\n",
      "epoch: 50, loss: 0.31504, err: 0.50445, test_err: 0.24260, elapsed: 32.35\n",
      "epoch: 60, loss: 0.29908, err: 0.48748, test_err: 0.15760, elapsed: 32.01\n",
      "epoch: 70, loss: 0.27011, err: 0.44315, test_err: 0.33660, elapsed: 32.00\n",
      "epoch: 80, loss: 0.25139, err: 0.41032, test_err: 0.19440, elapsed: 32.21\n",
      "epoch: 90, loss: 0.23057, err: 0.38295, test_err: 0.26060, elapsed: 32.99\n",
      "epoch: 100, loss: 0.21088, err: 0.35288, test_err: 0.18230, elapsed: 32.90\n"
     ]
    }
   ],
   "source": [
    "train(100, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training progress was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.541Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !tensorboard --logdir logdir2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained network - prepare test input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expr:    ['1', '2', '3', '+', '4', '5', '6']\n",
      "ans:     ['=', '5', '7', '9']\n",
      "target:  ['5', '7', '9', ' ']\n"
     ]
    }
   ],
   "source": [
    "t1, op, t2        = '123', '+', '456'\n",
    "\n",
    "expr              = t1 + op + t2\n",
    "ans               = '='+str(eval(expr))\n",
    "target            = (ans+' ')[1:]\n",
    "\n",
    "print('expr:   ',[c for c in expr])\n",
    "print('ans:    ',[c for c in ans])\n",
    "print('target: ',[c for c in target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained network - prepare test input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.545Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_encoder_input = [one_hot(symbol_map[c]) \\\n",
    "                      for c in expr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_encoder_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encoder_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test trained network - run encoder\n",
    "\n",
    "- 7 개의 입력 시퀀스를 넣음\n",
    "\n",
    "  - batch size = 1\n",
    "  \n",
    "  - `encoder_seqlen` : [7]\n",
    "\n",
    "  - `encoder_inputs` : `test_encoder_input`\n",
    "    - `'1', '2', '3', '+', '4', '5', '6'` 에 대한 인덱스 값들을 one-hot encoding\n",
    "\n",
    "  - `encoder_training` : False (dropout_rate 를 0.0 으로 설정)\n",
    "  \n",
    "- encoder 의 출력:\n",
    "\n",
    "  - `encoder_out` : encoder RNN 의 매 batch, 매 sequence 마다의 출력. **사용하지않음**\n",
    "  \n",
    "  - `encoder_state` : 입력된 연산식의 계산 결과값에 대한 _representation_ 이 들어 있다고 여겨지는 값\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.550Z"
    }
   },
   "outputs": [],
   "source": [
    "feed = {\n",
    "    encoder_seqlen: [encoder_max_seq_len],\n",
    "    encoder_inputs: [test_encoder_input],\n",
    "    encoder_training: False\n",
    "}\n",
    "e_out, e_state = sess.run(\n",
    "                    [encoder_out, encoder_state],\n",
    "                    feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 7, 100), tuple)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_out.shape, type(e_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained network - First Decoder Run\n",
    "\n",
    "- `answer` : 결과 값을 문자로 받기 위한 7자 버퍼\n",
    "\n",
    "- `answer` 값이 decoder의 초기 입력으로 제공됨\n",
    "\n",
    "- `answer` 값이 decoder 초기 입력이 될 때, 첫 심볼이 `'='` 이어야 함. 나머지는 don't care\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['=', ' ', ' ', ' ', ' ']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ['='] + [c for c in '    ']\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Inputs/Outputs\n",
    "\n",
    "- `encoder_state` : 계산결과의 _representation_ 이 들어있다고 생각되는, encoder network 의 최종 상태\n",
    "\n",
    "- `decoder_seqlen` : 루프 한 스텝에서 입력할 디코더 시퀀스 길이\n",
    "    \n",
    "- `decoder_inputs` : 루프 한 스텝 분량의 디코더 입력값\n",
    "\n",
    "- `decoder_state` : decoder RNN 의 한 스텝 진행 후의 상태. 다음 스텝을 진행할 때 decoder initial state 로 제시 해야 하는 값\n",
    "\n",
    "- `decoder_out` : decoder RNN 의 직접 출력. **사용하지않음**. 이 값을 FCN 으로 보내 나오는 `outputs` 가 실제 출력\n",
    "\n",
    "- `outputs` : 최종 one-hot output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.554Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed = {\n",
    "    encoder_state: e_state,\n",
    "    decoder_seqlen: [1],\n",
    "    decoder_inputs: [[one_hot(symbol_map[c]) \\\n",
    "                      for c in answer]]\n",
    "}\n",
    "out, d_out, d_state = sess.run(\n",
    "                        [outputs,\n",
    "                         decoder_out,\n",
    "                         decoder_state],\n",
    "                        feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 5, 13), (1, 5, 100))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, d_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_max(out[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols[arg_max(out[0,0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained network - Repeated Decoder Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.559Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digit = symbols[arg_max(out[0,0])]\n",
    "collect_answer = [digit]\n",
    "for _ in range(1,decoder_max_seq_len):\n",
    "    feed = {\n",
    "        encoder_state: d_state,\n",
    "        decoder_seqlen: [1],\n",
    "        decoder_inputs: [[one_hot(symbol_map[c]) \\\n",
    "                          for c in answer]]\n",
    "    }\n",
    "    out, d_out, d_state = \\\n",
    "        sess.run([outputs, decoder_out, decoder_state],\n",
    "                 feed)\n",
    "    digit = symbols[arg_max(out[0,0])]\n",
    "    collect_answer.append(digit)\n",
    "    answer[0] = digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '8', '0', ' ', ' ']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Wrap-up: infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.562Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer(expr):\n",
    "    # encoder\n",
    "    feed = {\n",
    "        encoder_seqlen: [len(expr)],\n",
    "        encoder_inputs: \\\n",
    "            [str_to_onehot(expr,encoder_max_seq_len)],\n",
    "        encoder_training: False\n",
    "    }\n",
    "    e_out, e_state = \\\n",
    "        sess.run([encoder_out, encoder_state], feed)\n",
    "    \n",
    "    # decoder: step 0\n",
    "    out_buf = []\n",
    "    feed = {\n",
    "        encoder_state: e_state,\n",
    "        decoder_seqlen: [1],\n",
    "        decoder_inputs: \\\n",
    "            [str_to_onehot('=',decoder_max_seq_len)]\n",
    "    }\n",
    "    out, d_state = sess.run([outputs, decoder_state], feed)\n",
    "    out_decoded = onehot_to_str(out[0],1)\n",
    "    out_buf.append(out_decoded)\n",
    "    \n",
    "    # decoder: step 1..n-1\n",
    "    for _ in range(1,decoder_max_seq_len):\n",
    "        feed = {\n",
    "            encoder_state: d_state,\n",
    "            decoder_seqlen: [1],\n",
    "            decoder_inputs: \\\n",
    "                [str_to_onehot(out_decoded,decoder_max_seq_len)]\n",
    "        }\n",
    "        out, d_state = sess.run([outputs, decoder_state], feed)\n",
    "        out_decoded = onehot_to_str(out[0],1)\n",
    "        out_buf.append(out_decoded)\n",
    "\n",
    "    return ''.join(out_buf), e_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'456  '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, e_out = infer('345+111')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'567  '"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, e_out = infer('345+222')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'333  '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, e_out = infer('111+222')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.567Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1541 ] [1541 ] 905+636\n",
      "[996  ] [996  ] 525+471\n",
      "[662  ] [662  ] 61+601\n",
      "[1016 ] [1016 ] 29+987\n",
      "[830  ] [830  ] 286+544\n",
      "[796  ] [795  ] 78+718\n",
      "[437  ] [437  ] 408+29\n",
      "[1422 ] [1422 ] 488+934\n",
      "[869  ] [868  ] 861+8\n",
      "[1237 ] [1237 ] 428+809\n",
      "[1281 ] [1280 ] 986+295\n",
      "[1445 ] [1445 ] 610+835\n",
      "[1482 ] [1482 ] 616+866\n",
      "[121  ] [110  ] 75+46\n",
      "[1265 ] [1265 ] 286+979\n",
      "[1067 ] [1067 ] 552+515\n",
      "[1141 ] [1141 ] 504+637\n",
      "[1548 ] [1548 ] 949+599\n",
      "[1336 ] [1336 ] 758+578\n",
      "[349  ] [349  ] 196+153\n",
      "[803  ] [803  ] 203+600\n",
      "[933  ] [933  ] 722+211\n",
      "[325  ] [325  ] 73+252\n",
      "[1496 ] [1496 ] 684+812\n",
      "[629  ] [629  ] 82+547\n",
      "[1162 ] [1162 ] 285+877\n",
      "[568  ] [568  ] 448+120\n",
      "[575  ] [575  ] 156+419\n",
      "[1524 ] [1524 ] 666+858\n",
      "[873  ] [873  ] 670+203\n",
      "[1386 ] [1386 ] 479+907\n",
      "[856  ] [855  ] 834+22\n",
      "[1154 ] [1153 ] 624+530\n",
      "[646  ] [645  ] 584+62\n",
      "[1244 ] [1234 ] 990+254\n",
      "[665  ] [664  ] 169+496\n",
      "[140  ] [131  ] 133+7\n",
      "[626  ] [622  ] 623+3\n",
      "[674  ] [674  ] 66+608\n",
      "[1234 ] [1234 ] 253+981\n",
      "[1016 ] [1016 ] 684+332\n",
      "[1208 ] [1208 ] 460+748\n",
      "[1100 ] [1090 ] 949+151\n",
      "[644  ] [644  ] 444+200\n",
      "[864  ] [864  ] 351+513\n",
      "[354  ] [344  ] 95+259\n",
      "[57  ] [59   ] 56+1\n",
      "[833  ] [833  ] 52+781\n",
      "[1254 ] [1254 ] 601+653\n",
      "[1099 ] [1099 ] 194+905\n",
      "[220  ] [210  ] 193+27\n",
      "[1152 ] [1152 ] 929+223\n",
      "[1119 ] [1119 ] 319+800\n",
      "[1027 ] [1027 ] 316+711\n",
      "[208  ] [218  ] 102+106\n",
      "[990  ] [980  ] 57+933\n",
      "[943  ] [942  ] 289+654\n",
      "[1376 ] [1376 ] 683+693\n",
      "[1348 ] [1348 ] 517+831\n",
      "[586  ] [586  ] 127+459\n",
      "[1210 ] [1210 ] 395+815\n",
      "[1689 ] [1689 ] 727+962\n",
      "[579  ] [579  ] 25+554\n",
      "[505  ] [404  ] 388+117\n",
      "[910  ] [910  ] 543+367\n",
      "[993  ] [993  ] 373+620\n",
      "[1388 ] [1388 ] 539+849\n",
      "[585  ] [585  ] 314+271\n",
      "[1220 ] [1220 ] 330+890\n",
      "[1256 ] [1256 ] 533+723\n",
      "[1961 ] [1961 ] 997+964\n",
      "[1209 ] [1219 ] 508+701\n",
      "[1040 ] [1040 ] 807+233\n",
      "[873  ] [873  ] 116+757\n",
      "[870  ] [870  ] 841+29\n",
      "[714  ] [714  ] 240+474\n",
      "[446  ] [435  ] 396+50\n",
      "[503  ] [603  ] 0+503\n",
      "[593  ] [583  ] 49+544\n",
      "[705  ] [604  ] 497+208\n",
      "[1862 ] [1862 ] 932+930\n",
      "[1467 ] [1467 ] 979+488\n",
      "[1783 ] [1783 ] 950+833\n",
      "[676  ] [676  ] 531+145\n",
      "[1514 ] [1514 ] 641+873\n",
      "[511  ] [511  ] 171+340\n",
      "[670  ] [670  ] 204+466\n",
      "[970  ] [970  ] 120+850\n",
      "[1006 ] [1006 ] 618+388\n",
      "[902  ] [902  ] 785+117\n",
      "[1187 ] [1187 ] 200+987\n",
      "[1050 ] [1050 ] 485+565\n",
      "[433  ] [433  ] 200+233\n",
      "[1045 ] [1045 ] 413+632\n",
      "[498  ] [497  ] 169+329\n",
      "[897  ] [897  ] 688+209\n",
      "[1066 ] [1067 ] 121+945\n",
      "[254  ] [254  ] 243+11\n",
      "[935  ] [935  ] 524+411\n",
      "[1318 ] [1318 ] 406+912\n",
      "errs: 0.26000\n"
     ]
    }
   ],
   "source": [
    "errs = []\n",
    "for _ in range(100):\n",
    "    expr, ans_ = make_random_data()\n",
    "    truth = (ans_+' ')[1:6]\n",
    "    ans, e_out  = infer(expr)\n",
    "    print('['+truth+']', '['+ans+']', expr)\n",
    "    errs.append(0 if truth == ans else 1)\n",
    "print('errs: {:.5f}'.format(np.mean(errs,dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN activation visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.569Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f23142d09d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAD8CAYAAADHaDe8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23513c5090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.array(e_out.transpose() * 127 + 128,dtype=np.int32),\n",
    "           cmap='gray',\n",
    "           aspect=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logdir2/encoder_decoder/save'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(tf.get_default_session(), 'logdir2/encoder_decoder/save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2608\r\n",
      "-rw-rw-r-- 1 user01 user01      65 10월 11 14:28 checkpoint\r\n",
      "-rw-rw-r-- 1 user01 user01  893580 10월 11 14:22 events.out.tfevents.1507699097.student14\r\n",
      "-rw-rw-r-- 1 user01 user01 1254164 10월 11 14:28 save.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 user01 user01    1677 10월 11 14:28 save.index\r\n",
      "-rw-rw-r-- 1 user01 user01  505854 10월 11 14:28 save.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l logdir2/encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.572Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess,tf.train.latest_checkpoint('logdir/rnn1'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
