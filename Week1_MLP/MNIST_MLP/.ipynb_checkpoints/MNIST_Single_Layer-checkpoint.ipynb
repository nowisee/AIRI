{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "imageNum = 60000\n",
    "testImageNum = 10000\n",
    "typesOfNumber = 10\n",
    "row = 28\n",
    "col = 28\n",
    "batchSize = 256\n",
    "batchCount = imageNum // batchSize\n",
    "\n",
    "learningRate = 0.05\n",
    "iteration = 100\n",
    "\n",
    "##\n",
    "X = tf.placeholder(shape=[None, row*col], dtype=tf.float32, name='X')\n",
    "Y = tf.placeholder(shape=[None], dtype=tf.int64, name='Y')\n",
    "Y_onehot = tf.one_hot(Y, typesOfNumber, axis=1)\n",
    "\n",
    "W = tf.Variable(tf.zeros([row*col, typesOfNumber]))\n",
    "B = tf.Variable(tf.zeros([typesOfNumber]))\n",
    "weight = tf.zeros([row*col, typesOfNumber])\n",
    "\n",
    "##\n",
    "Y_pred = tf.matmul(X, W) + B\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Y_pred, labels=Y_onehot))\n",
    "Y_pred_softmax = tf.nn.softmax(Y_pred)\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learningRate)\n",
    "optimizer = trainer.minimize(loss)\n",
    "\n",
    "correct = tf.equal(tf.argmax(Y_pred_softmax, 1), tf.argmax(Y_onehot, 1))\n",
    "acc = tf.reduce_mean(tf.cast(correct, tf.float32))    \n",
    "\n",
    "saver = tf.train.Saver()\n",
    "path = './models/simple_nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch_0001: 211.422145 , acc =  0.863934\n",
      "epoch_0002: 120.389694 , acc =  0.879801\n",
      "epoch_0003: 104.316150 , acc =  0.888018\n",
      "epoch_0004: 96.400456 , acc =  0.892884\n",
      "epoch_0005: 91.450463 , acc =  0.896651\n",
      "epoch_0006: 87.970800 , acc =  0.899718\n",
      "epoch_0007: 85.346884 , acc =  0.901651\n",
      "epoch_0008: 83.273334 , acc =  0.903251\n",
      "epoch_0009: 81.578874 , acc =  0.904784\n",
      "epoch_0010: 80.158948 , acc =  0.906118\n",
      "epoch_0011: 78.945588 , acc =  0.907118\n",
      "epoch_0012: 77.892409 , acc =  0.908451\n",
      "epoch_0013: 76.966503 , acc =  0.909334\n",
      "epoch_0014: 76.143772 , acc =  0.910118\n",
      "epoch_0015: 75.406098 , acc =  0.911251\n",
      "epoch_0016: 74.739553 , acc =  0.912084\n",
      "epoch_0017: 74.133225 , acc =  0.912851\n",
      "epoch_0018: 73.578423 , acc =  0.913618\n",
      "epoch_0019: 73.068121 , acc =  0.914184\n",
      "epoch_0020: 72.596574 , acc =  0.914801\n",
      "epoch_0021: 72.159023 , acc =  0.915051\n",
      "epoch_0022: 71.751495 , acc =  0.915534\n",
      "epoch_0023: 71.370640 , acc =  0.916018\n",
      "epoch_0024: 71.013604 , acc =  0.916318\n",
      "epoch_0025: 70.677951 , acc =  0.916734\n",
      "epoch_0026: 70.361576 , acc =  0.917134\n",
      "epoch_0027: 70.062653 , acc =  0.917584\n",
      "epoch_0028: 69.779594 , acc =  0.917818\n",
      "epoch_0029: 69.511003 , acc =  0.918101\n",
      "epoch_0030: 69.255650 , acc =  0.918434\n",
      "epoch_0031: 69.012450 , acc =  0.918768\n",
      "epoch_0032: 68.780438 , acc =  0.919151\n",
      "epoch_0033: 68.558751 , acc =  0.919251\n",
      "epoch_0034: 68.346618 , acc =  0.919351\n",
      "epoch_0035: 68.143348 , acc =  0.919334\n",
      "epoch_0036: 67.948319 , acc =  0.919668\n",
      "epoch_0037: 67.760964 , acc =  0.920018\n",
      "epoch_0038: 67.580775 , acc =  0.920318\n",
      "epoch_0039: 67.407287 , acc =  0.920601\n",
      "epoch_0040: 67.240078 , acc =  0.920918\n",
      "epoch_0041: 67.078761 , acc =  0.920934\n",
      "epoch_0042: 66.922984 , acc =  0.920918\n",
      "epoch_0043: 66.772422 , acc =  0.921084\n",
      "epoch_0044: 66.626778 , acc =  0.921218\n",
      "epoch_0045: 66.485778 , acc =  0.921401\n",
      "epoch_0046: 66.349168 , acc =  0.921584\n",
      "epoch_0047: 66.216714 , acc =  0.921634\n",
      "epoch_0048: 66.088198 , acc =  0.921818\n",
      "epoch_0049: 65.963422 , acc =  0.921901\n",
      "epoch_0050: 65.842198 , acc =  0.922168\n",
      "epoch_0051: 65.724352 , acc =  0.922284\n",
      "epoch_0052: 65.609722 , acc =  0.922418\n",
      "epoch_0053: 65.498157 , acc =  0.922534\n",
      "epoch_0054: 65.389515 , acc =  0.922701\n",
      "epoch_0055: 65.283666 , acc =  0.922768\n",
      "epoch_0056: 65.180484 , acc =  0.922951\n",
      "epoch_0057: 65.079852 , acc =  0.923101\n",
      "epoch_0058: 64.981664 , acc =  0.923334\n",
      "epoch_0059: 64.885816 , acc =  0.923401\n",
      "epoch_0060: 64.792211 , acc =  0.923651\n",
      "epoch_0061: 64.700758 , acc =  0.923851\n",
      "epoch_0062: 64.611371 , acc =  0.923884\n",
      "epoch_0063: 64.523970 , acc =  0.923968\n",
      "epoch_0064: 64.438478 , acc =  0.924034\n",
      "epoch_0065: 64.354822 , acc =  0.924218\n",
      "epoch_0066: 64.272934 , acc =  0.924251\n",
      "epoch_0067: 64.192748 , acc =  0.924401\n",
      "epoch_0068: 64.114203 , acc =  0.924534\n",
      "epoch_0069: 64.037241 , acc =  0.924601\n",
      "epoch_0070: 63.961806 , acc =  0.924701\n",
      "epoch_0071: 63.887844 , acc =  0.924768\n",
      "epoch_0072: 63.815306 , acc =  0.924868\n",
      "epoch_0073: 63.744144 , acc =  0.924918\n",
      "epoch_0074: 63.674313 , acc =  0.925068\n",
      "epoch_0075: 63.605767 , acc =  0.925151\n",
      "epoch_0076: 63.538467 , acc =  0.925268\n",
      "epoch_0077: 63.472372 , acc =  0.925334\n",
      "epoch_0078: 63.407445 , acc =  0.925368\n",
      "epoch_0079: 63.343649 , acc =  0.925418\n",
      "epoch_0080: 63.280950 , acc =  0.925451\n",
      "epoch_0081: 63.219314 , acc =  0.925368\n",
      "epoch_0082: 63.158710 , acc =  0.925568\n",
      "epoch_0083: 63.099108 , acc =  0.925634\n",
      "epoch_0084: 63.040478 , acc =  0.925684\n",
      "epoch_0085: 62.982792 , acc =  0.925751\n",
      "epoch_0086: 62.926024 , acc =  0.925818\n",
      "epoch_0087: 62.870147 , acc =  0.925851\n",
      "epoch_0088: 62.815138 , acc =  0.925968\n",
      "epoch_0089: 62.760971 , acc =  0.926018\n",
      "epoch_0090: 62.707626 , acc =  0.926068\n",
      "epoch_0091: 62.655078 , acc =  0.926101\n",
      "epoch_0092: 62.603309 , acc =  0.926201\n",
      "epoch_0093: 62.552295 , acc =  0.926301\n",
      "epoch_0094: 62.502019 , acc =  0.926368\n",
      "epoch_0095: 62.452461 , acc =  0.926451\n",
      "epoch_0096: 62.403603 , acc =  0.926501\n",
      "epoch_0097: 62.355428 , acc =  0.926501\n",
      "epoch_0098: 62.307919 , acc =  0.926601\n",
      "epoch_0099: 62.261059 , acc =  0.926701\n",
      "epoch_0100: 62.214832 , acc =  0.926684\n"
     ]
    }
   ],
   "source": [
    "if sys.argv[1] == 'train':\n",
    "    ##\n",
    "    fileobj = open('train-images.idx3-ubyte')\n",
    "    images = np.fromfile(file=fileobj, dtype=np.uint8)\n",
    "    images = images[16:].reshape([imageNum, row*col]).astype(np.float)\n",
    "\n",
    "    fileobj = open('train-labels.idx1-ubyte')\n",
    "    labels = np.fromfile(file=fileobj, dtype=np.uint8)\n",
    "    labels = labels[8:].reshape([imageNum]).astype(np.int)\n",
    "    \n",
    "    ##\n",
    "    images = images / 255.0\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(iteration):\n",
    "            total_loss = 0  \n",
    "\n",
    "            for i in range(batchCount):\n",
    "                batchIndex = i * batchSize\n",
    "                img = np.reshape(images[batchIndex:batchIndex+batchSize], [batchSize, row*col])\n",
    "                label = labels[batchIndex:batchIndex+batchSize]\n",
    "                _, loss_v = sess.run([optimizer, loss], feed_dict={X:img, Y:label})\n",
    "                total_loss += loss_v\n",
    "\n",
    "            saver.save(sess, path)\n",
    "            print 'epoch_%04d: %.6f' %(epoch+1, total_loss), ', acc = ', acc.eval(session=sess, feed_dict={X:images, Y:labels})\n",
    "            \n",
    "        #print'Test image acc = ', acc.eval(session=sess, feed_dict={X:test_images, Y:test_labels})\n",
    "\n",
    "        trained_weight = sess.run(W)\n",
    "    \n",
    "    ##\n",
    "    trained_weight = np.transpose(trained_weight)\n",
    "    weight = (trained_weight).reshape([typesOfNumber, row, col]).astype(np.float32)\n",
    "\n",
    "    for i in range(typesOfNumber):\n",
    "        maxVal = np.max(weight[i])\n",
    "        minVal = np.min(weight[i])\n",
    "        weight[i] = 255 * (weight[i] - minVal) / (maxVal-minVal)\n",
    "        name = 'weight' + str(i) + '.jpg'\n",
    "        scipy.misc.imsave(name, weight[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/simple_nn_epoch234\n",
      "Test image acc =  0.9238\n",
      "INFO:tensorflow:Restoring parameters from ./models/simple_nn_epoch234\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "if sys.argv[1] == 'test':\n",
    "    if sys.argv[2] == 'MNIST_data':\n",
    "        fileobj = open('t10k-images.idx3-ubyte')\n",
    "        test_images = np.fromfile(file=fileobj, dtype=np.uint8)\n",
    "        test_images = test_images[16:].reshape([testImageNum, row*col]).astype(np.float)\n",
    "\n",
    "        fileobj = open('t10k-labels.idx1-ubyte')\n",
    "        test_labels = np.fromfile(file=fileobj, dtype=np.uint8)\n",
    "        test_labels = test_labels[8:].reshape([testImageNum]).astype(np.int)\n",
    "        \n",
    "        test_images = test_images / 255.0\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, path)\n",
    "            print'Test image acc = ', acc.eval(session=sess, feed_dict={X:test_images, Y:test_labels})\n",
    "        \n",
    "    else:\n",
    "        test_image = scipy.misc.imread(sys.argv[2])\n",
    "        test_image = test_image.reshape([1, row*col])\n",
    "        test_image = test_image / 255.0\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, path)\n",
    "            np_Y_pred_softmax = sess.run(Y_pred_softmax, feed_dict={X:test_image})\n",
    "            \n",
    "            for i in range(typesOfNumber):\n",
    "                if np_Y_pred_softmax[0][i] == np_Y_pred_softmax.max():\n",
    "                    print i\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
