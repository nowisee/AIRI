{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 기초 예제 - MNIST 문제 해결 구현\n",
    "\n",
    "1. RNN 모형\n",
    "1. RNN 학습 데이터로 사용하기 위한 mini-batch 구성\n",
    "1. 텐서플로우 RNN\n",
    "1. mnist 데이터 준비\n",
    "1. 1-layer RNN 학습 테스트\n",
    "1. stacked rnn in tensorflow\n",
    "1. 3-layer RNN 학습 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모형\n",
    "\n",
    "<img  src=\"rnn.jpg\" style=\"width:55.5rem\"/>\n",
    "\n",
    "<center>이미지 출처: http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/</center>\n",
    "\n",
    "\\begin{align}\n",
    "s_t & = tanh(Ux_t + Ws_{t-1}) \\\\\n",
    "o_t & = softmax(Vs_t) \\\\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 mini-batch 구성의 차이 FCN, 2D-CNN vs RNN\n",
    "\n",
    "- FCN ( Fully Connected Network, a.k.a. `dense` )\n",
    "\n",
    "  - `[batch, inputs]`\n",
    "  - e.g.: [`tf.layers.dense()`](http://devdocs.io/tensorflow~python/tf/layers/dense)\n",
    "\n",
    "\n",
    "- 2D-CNN 의 경우 학습데이터 feed 구성\n",
    "\n",
    "  - `[batch, height, width, channel]` : `data_format = \"NHWC\"` (default)\n",
    "  - `[batch, channel, height, width]` : `data_format = \"NCHW\"`\n",
    "  - e.g.: [`tf.layers.conv2d()`](http://devdocs.io/tensorflow~python/tf/layers/conv2d)\n",
    "\n",
    "\n",
    "\n",
    "- RNN 의 경우 학습 데이터 feed 구성\n",
    "\n",
    "  - `[batch, sequence, input]` : `time_major = False` (default for [`tf.nn.dynamic_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/dynamic_rnn))\n",
    "  - `[sequence, batch, input]` : `time_major = True`  (default for [`tf.nn.static_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/static_rnn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모형과 tensorflow RNNCell\n",
    "\n",
    "\n",
    "<img  src=\"Selection_20170914_161757_e791.png\"/>\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "s_t & = tanh(Ux_t + Ws_{t-1}) \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "- **_V_** 에 해당하는 구조가 없음\n",
    "\n",
    "- **_softmax()_** 도 없음\n",
    "\n",
    "- **_V_** 와 **_softmax()_** 는 필요할 때만 만들어서 붙이면 됨 ( `tf.layers.dense`, `tf.nn.softmax` )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우 rnn 기본 클래스/함수\n",
    "\n",
    "- [`tf.contrib.rnn.BasicRNNCell()`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/basicrnncell)\n",
    "  - abstraction of RNN cell\n",
    "  - $s_t = tanh(Ux_t + Ws_{t-1})$\n",
    "\n",
    "\n",
    "\n",
    "- [`tf.nn.static_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/static_rnn)\n",
    "  - _time-major_ format inputs, outputs\n",
    "  - static unfolding\n",
    "\n",
    "\n",
    "- [`tf.nn.dynamic_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/dynamic_rnn)\n",
    "  - _batch-major_ format inputs, outputs (default)\n",
    "  - `time_major = True` for _time-major_ format\n",
    "  - dynamic unfolding using [`tf.while_loop()`](http://devdocs.io/tensorflow~python/tf/while_loop)\n",
    "  - more advanced options\n",
    "\n",
    "\n",
    "\n",
    "### [`tf.contrib.rnn.BasicRNNCell()`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/basicrnncell)\n",
    "\n",
    "<code>\n",
    "    `__init__`(\n",
    "        <span style=\"color:red\">num_units,</span>\n",
    "        activation=None,\n",
    "        reuse=None\n",
    "    )\n",
    "</code>\n",
    "\n",
    "<code>\n",
    "    `__call__`(\n",
    "        <span style=\"color:red\">inputs,</span>\n",
    "        <span style=\"color:red\">state,</span>\n",
    "        scope=None\n",
    "    )\n",
    "</code>\n",
    "\n",
    "### [`tf.nn.static_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/static_rnn)\n",
    "\n",
    "<code>\n",
    "    static_rnn(\n",
    "        <span style=\"color:red\">cell,</span>\n",
    "        <span style=\"color:red\">inputs,</span>\n",
    "        initial_state=None,\n",
    "        dtype=None,\n",
    "        <span style=\"color:red\">sequence_length=None,</span>\n",
    "        scope=None\n",
    "    )\n",
    "</code>\n",
    "\n",
    "> The simplest form of RNN network generated is:\n",
    "\n",
    "<code>\n",
    "    state = cell.zero_state(...)\n",
    "    outputs = []\n",
    "    for inp in inputs:\n",
    "      <span style=\"color:red\">output, state = cell(inp, state)</span>\n",
    "      outputs.append(output)\n",
    "    return (outputs, state)\n",
    "</code>\n",
    "\n",
    "> `sequence_length` 가 `None` 이 아니라면,\n",
    "> 배치에 포함된 각 example 들의 sequence length 를 기록한 리스트를 전달.\n",
    "> 해당 배치에서 sequence length 를 넘는 t 에 대해서는:\n",
    ">   - <span style=\"color:red\">output 은 zero</span>\n",
    ">   - state는 sequence length - 1 때의 state\n",
    "\n",
    "```\n",
    "(output, state)(b, t) =\n",
    "  (t >= sequence_length(b))\n",
    "    ? (zeros(cell.output_size), states(b, sequence_length(b) - 1))\n",
    "    : cell(input(b, t), state(b, t - 1))\n",
    "``` \n",
    "    \n",
    "\n",
    "### [`tf.nn.dynamic_rnn()`](http://devdocs.io/tensorflow~python/tf/nn/dynamic_rnn)\n",
    "\n",
    "<code>\n",
    "dynamic_rnn(\n",
    "    <span style=\"color:red\">cell,</span>\n",
    "    <span style=\"color:red\">inputs,</span>\n",
    "    <span style=\"color:red\">sequence_length=None,</span>\n",
    "    initial_state=None,\n",
    "    dtype=None,\n",
    "    parallel_iterations=None,\n",
    "    swap_memory=False,\n",
    "    time_major=False,\n",
    "    scope=None\n",
    ")\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@media print {\n",
       "  a[href]:after {\n",
       "    content: none !important;\n",
       "  }\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext do_not_print_href\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr logdir\n",
    "!mkdir -p logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "- 1주차 실습에 사용한 것과 동일한 데이터\n",
    "- 5주차 실습에서는 tensorflow example 의 기본 제공 메소드를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1주차에 사용한 코드 (참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"border:1px solid black;border-radius:3px;width:65.0rem;margin:auto\">\n",
    "<code>\n",
    "    %%bash\n",
    "    test -s ./mnist/train-images-idx3-ubyte || (\n",
    "     mkdir -p ./mnist\n",
    "     cd ./mnist\n",
    "     echo \"$(pwd)\"\n",
    "     wget -q \\\n",
    "      http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz \\\n",
    "      http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz \\\n",
    "      http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz \\\n",
    "      http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "     gzip -d *.gz\n",
    "    )\n",
    "\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"border:1px solid black;border-radius:3px;width:65.0rem;margin:auto\">\n",
    "<code>\n",
    "    data_dir = './mnist'\n",
    "    data_dir\n",
    "\n",
    "    images         = np.fromfile(data_dir + \n",
    "                         '/train-images-idx3-ubyte',dtype=np.uint8)\n",
    "    images         = images[16:].reshape([-1,28,28]).astype(np.float32)\n",
    "    images         = images / 127.0 - 1.0\n",
    "\n",
    "    labels         = np.fromfile(data_dir + \n",
    "                         '/train-labels-idx1-ubyte',dtype=np.uint8)\n",
    "    labels         = labels[8:].astype(np.int64)\n",
    "\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"border:1px solid black;border-radius:3px;width:65.0rem;margin:auto\">\n",
    "<code>\n",
    "    images.shape, images.dtype, labels.shape, labels.dtype\n",
    "\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5주차에 사용할 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist.input_data \\\n",
    "    import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f3761398150>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f3702676350>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f3702676390>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = read_data_sets('./mnist', one_hot=False)\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, (55000, 784), (55000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples, \\\n",
    "mnist.train.images.shape, \\\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, (10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples, \\\n",
    "mnist.test.images.shape, \\\n",
    "mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 하나만 골라서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3702676e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "img = mnist.test.images[i,:].reshape([28,28])\n",
    "lbl = mnist.test.labels[i]\n",
    "plt.matshow(img,cmap=plt.get_cmap('gray'))\n",
    "plt.title('train[{:d}]: label={:d}'.format(i,lbl))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 학습 입력으로 사용하기 위해서 입력값의 해석 방식을 달리함\n",
    "\n",
    "- 28 x 28 = 784 개 입력값을\n",
    "\n",
    "- 28개 입력값의 길이 28인 시퀀스로 해석\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터의 규격 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_UNITS = 28\n",
    "NUM_HIDDEN_UNITS = 31\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 카운트 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 78)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop_count = mnist.train.num_examples // BATCH_SIZE\n",
    "test_loop_count  = mnist.test.num_examples // BATCH_SIZE\n",
    "\n",
    "train_loop_count, test_loop_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 만들고자 하는 RNN 네트워크 구조\n",
    "\n",
    "<img  src=\"Selection_20170912_110940_c175.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistRnn:\n",
    "    def __init__(self, \n",
    "                 inputs, \n",
    "                 labels, \n",
    "                 input_units, \n",
    "                 num_hidden_units, \n",
    "                 batch_size, \n",
    "                 max_seq_len):\n",
    "        '''\n",
    "        inputs: in shape [batch_size, max_seq_len, input_size]\n",
    "        labels: in shape [batch_size]\n",
    "        '''\n",
    "        \n",
    "        # RNN 모델 구성\n",
    "        cell            = tf.contrib.rnn.BasicRNNCell(\n",
    "                            num_hidden_units)\n",
    "        sequence_length = [max_seq_len] * batch_size\n",
    "        last, states    = tf.nn.dynamic_rnn(\n",
    "                            cell, \n",
    "                            inputs, \n",
    "                            sequence_length=sequence_length, \n",
    "                            dtype=tf.float32)\n",
    "\n",
    "        ######################################################\n",
    "        # last.shape   : \n",
    "        #  [batch_size, max_seq_len, num_hidden_units]\n",
    "        # states.shape : \n",
    "        #  [?, num_hidden_units]\n",
    "        ######################################################\n",
    "        print('last.shape', last.get_shape().as_list())\n",
    "        print('states', states)\n",
    "\n",
    "\n",
    "        \n",
    "        ######################################################\n",
    "        # max_seq_len 축으로 0~27 까지 값 중에 0~26 출력 값은 사용하지\n",
    "        #  않음 - 모든 RNN이 그런건 아니고 경우에 따라 다름\n",
    "        # last.shape      : \n",
    "        #  [batch_size, max_seq_len, num_hidden_units]\n",
    "        # rnn_output shape: \n",
    "        #  [batch_size, num_hidden_units]\n",
    "        ######################################################\n",
    "        rnn_output = last[:,max_seq_len-1,:]\n",
    "        print('rnn_output.shape', rnn_output.get_shape().as_list())\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 10 개의 output units 로 만들 \n",
    "        #  FCN (fully-connected-network) 구성\n",
    "        # outputs shape will become: [batch_size, 10]\n",
    "        outputs    = tf.layers.dense(rnn_output, 10)\n",
    "        print('outputs.shape', outputs.get_shape().as_list())\n",
    "\n",
    "        \n",
    "        ######################################################\n",
    "        # loss 함수: sparse_softmax_cross_entropy\n",
    "        #   label 데이터의 one-hot encoding 과,\n",
    "        #   output 데이터의 softmax() 적용이,\n",
    "        #   sparse_softmax_cross_entropy() 함수 하나에 다 들어 있음\n",
    "        ######################################################\n",
    "\n",
    "\n",
    "        loss       = tf.losses.sparse_softmax_cross_entropy(\n",
    "                        labels, outputs)\n",
    "        optimize   = tf.train.AdamOptimizer(learning_rate=0.001). \\\n",
    "                        minimize(loss)\n",
    "\n",
    "        \n",
    "        # accuracy\n",
    "        preds    = tf.argmax(outputs, axis=1)\n",
    "        errors   = tf.count_nonzero(labels - preds)\n",
    "        accuracy = 1.0 - tf.cast(errors,tf.float32) / \\\n",
    "                         tf.cast(tf.size(preds),tf.float32)\n",
    "\n",
    "        # 클래스 객체 외부에서 참고할 수 있도록 속성으로 저장\n",
    "        self.outputs        = outputs\n",
    "        self.loss           = loss\n",
    "        self.optimize       = optimize\n",
    "        self.accuracy       = accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 그래프 초기화, Placeholders 정의, 그래프 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.shape [128, 28, 31]\n",
      "states Tensor(\"rnn/while/Exit_2:0\", shape=(128, 31), dtype=float32)\n",
      "rnn_output.shape [128, 31]\n",
      "outputs.shape [128, 10]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs_ = tf.placeholder(\n",
    "            tf.float32,\n",
    "            [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS],\n",
    "            name='inputs')\n",
    "labels_ = tf.placeholder(\n",
    "            tf.int64,\n",
    "            [BATCH_SIZE],\n",
    "            name='labels')\n",
    "\n",
    "model = MnistRnn(inputs_,\n",
    "                 labels_,\n",
    "                 INPUT_UNITS,\n",
    "                 NUM_HIDDEN_UNITS,\n",
    "                 BATCH_SIZE,\n",
    "                 MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습을 위한 세션 초기화, 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 진도 기록용 summary writer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorboard logdir 지정시, 지정된 디렉토리 아래에서 이벤트 파일을 모두 찾아서 그래프로 보여줌\n",
    "\n",
    "- 따라서, 공통의 parentdir ( 예: `logdir/train` 과 `logdir/test` 의 공통 parent 인 `logdir` ) 지정시 여러 그래프를 동시에 보여 줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter(\n",
    "    'logdir/train',\n",
    "    graph=tf.get_default_graph())\n",
    "test_writer  = tf.summary.FileWriter(\n",
    "    'logdir/test',\n",
    "    graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 팁: `tf.Summary()`, `tf.Summary.Value()` 를 이용하면 텐서를 만들지 않아도 summary를 기록할 수 있습니다.\n",
    "\n",
    "```\n",
    "    summary = tf.Summary(\n",
    "                value=[\n",
    "                    tf.Summary.Value(\n",
    "                        tag=tag,\n",
    "                        simple_value=value)])\n",
    "    writer.add_summary(summary, step)\n",
    "```\n",
    "\n",
    "- 하지만, histogram, audio, image 등에 적용하려면 번거로운 일이 있읍니다. 여기서는 scalar summary 만 사용\n",
    "- \"Logging to tensorboard with manually generated summaries (not relying on summary ops)\" 참고\n",
    "  - https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    inputs,\n",
    "    labels,\n",
    "    max_epochs,\n",
    "    train_writer=None,\n",
    "    test_writer=None):\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(max_epochs):\n",
    "\n",
    "        train_elapsed = []\n",
    "        train_losses = []\n",
    "        train_accuracy = []\n",
    "        for i in range(train_loop_count):\n",
    "            t_start     = time.time()\n",
    "            offs        = i * BATCH_SIZE\n",
    "            batch_input = \\\n",
    "                mnist.train.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                        MAX_SEQ_LEN,\n",
    "                                        INPUT_UNITS])\n",
    "            batch_label = \\\n",
    "                mnist.train.labels[offs:offs+BATCH_SIZE]\n",
    "            optimize, loss, accuracy, = \\\n",
    "                sess.run([model.optimize,\n",
    "                          model.loss,\n",
    "                          model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            train_losses.append(loss)\n",
    "            train_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            train_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if train_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='train_accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                        tf.Summary.Value(\n",
    "                            tag='loss',\n",
    "                            simple_value=loss\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                train_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 250 == 0:\n",
    "                print(('[trn] ep {:d}, step {:d}, ' + \n",
    "                       'loss {:f}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.mean(train_losses),\n",
    "                    np.amin(train_accuracy),\n",
    "                    np.mean(train_elapsed)))\n",
    "                train_losses = []\n",
    "                train_accuracy = []\n",
    "                train_elapsed = []\n",
    "\n",
    "        test_elapsed  = []\n",
    "        test_accuracy = []\n",
    "        for i in range(test_loop_count):\n",
    "            t_start     = time.time()\n",
    "            offs        = i * BATCH_SIZE\n",
    "            batch_input = \\\n",
    "                mnist.test.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                       MAX_SEQ_LEN,\n",
    "                                       INPUT_UNITS])\n",
    "            batch_label = \\\n",
    "                mnist.test.labels[offs:offs+BATCH_SIZE]\n",
    "            accuracy, = \\\n",
    "                sess.run([model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            test_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            test_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "            if test_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='test_accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                test_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 250 == 0:\n",
    "                print(('[tst] ep {:d}, ' +\n",
    "                       'step {:d}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.amin(test_accuracy),\n",
    "                    np.mean(test_elapsed)))\n",
    "                test_accuracy = []\n",
    "                test_elapsed  = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trn] ep 1, step 250, loss 1.662436, accu 0.085938, sec/iter 0.007257\n",
      "[tst] ep 1, step 500, accu 0.507812, sec/iter 0.002417\n",
      "[trn] ep 2, step 750, loss 0.892362, accu 0.531250, sec/iter 0.005681\n",
      "[tst] ep 2, step 1000, accu 0.601562, sec/iter 0.002177\n",
      "[trn] ep 3, step 1250, loss 0.639886, accu 0.671875, sec/iter 0.005539\n",
      "[tst] ep 3, step 1500, accu 0.710938, sec/iter 0.002244\n",
      "[trn] ep 4, step 1750, loss 0.507841, accu 0.734375, sec/iter 0.005601\n",
      "[tst] ep 4, step 2000, accu 0.750000, sec/iter 0.002200\n",
      "[trn] ep 5, step 2250, loss 0.433358, accu 0.765625, sec/iter 0.005575\n",
      "[tst] ep 5, step 2500, accu 0.773438, sec/iter 0.002220\n",
      "[trn] ep 6, step 2750, loss 0.390744, accu 0.773438, sec/iter 0.005693\n",
      "[tst] ep 6, step 3000, accu 0.812500, sec/iter 0.002339\n",
      "[trn] ep 7, step 3250, loss 0.357466, accu 0.796875, sec/iter 0.005553\n",
      "[tst] ep 7, step 3500, accu 0.820312, sec/iter 0.002375\n",
      "[trn] ep 8, step 3750, loss 0.334627, accu 0.820312, sec/iter 0.007004\n",
      "[tst] ep 8, step 4000, accu 0.851562, sec/iter 0.002168\n",
      "[trn] ep 9, step 4250, loss 0.317587, accu 0.812500, sec/iter 0.005603\n",
      "[tst] ep 9, step 4500, accu 0.859375, sec/iter 0.002242\n",
      "[trn] ep 10, step 4750, loss 0.302175, accu 0.820312, sec/iter 0.005568\n",
      "[tst] ep 10, step 5000, accu 0.890625, sec/iter 0.002365\n"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph().finalize()\n",
    "train(inputs_, labels_, 10, train_writer, test_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 진행 점검 - 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !tensorboard --ip 0.0.0.0 --logdir logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모델 구성(2) - Stacking Multiple RNN Cells\n",
    "\n",
    "- [`tf.contrib.rnn.MultiRNNCell`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/multirnncell)\n",
    "\n",
    "<code>\n",
    "    `__init__(`\n",
    "        <span style=\"color:red\">cells,</span>\n",
    "        state_is_tuple=True\n",
    "    )\n",
    "</code>\n",
    "\n",
    "> 주의: _**tensorflow**_ 1.0 이전과 1.1, 1.2 이후의 `cells` 값 지정의 의미가 달라짐\n",
    "\n",
    "  - (A) _**tensorflow**_ 1.0 이전:\n",
    "\n",
    "<code>\n",
    "    cell       = tf.contrib.rnn.BasicRNNCell(num_hidden_units)\n",
    "    multi_cell = tf.contrib.rnn.MultiRnnCell(<span style=\"color:red\">[cell] * 3</span>)\n",
    "</code>\n",
    "\n",
    "  - (B) _**tensorflow**_ 1.1:\n",
    "    - `ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.`\n",
    "    - **To fix:**\n",
    "      ```\n",
    "        multi_cell = tf.contrib.rnn.MultiRnnCell([ \\\n",
    "            tf.contrib.rnn.BasicRNNCell(num_hidden_units) \\\n",
    "            for k in range(3)])\n",
    "      ```\n",
    "\n",
    "  - _**tensorflow**_ 1.2 이후:\n",
    "    - (A)방식을 써도 `ValueError` 가 발생하지는 않지만, (A), (B) 의미가 달라짐\n",
    "    - (A)방식 : 3-layer rnn stack 을 만들지만, 각 셀의 weight 를 공유하게 된다.\n",
    "    - layer 마다 별개의 rnn cell 을 만들고 싶으면 (B) 방식으로.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistRnn:\n",
    "    def __init__(self, \n",
    "                 inputs, \n",
    "                 labels, \n",
    "                 input_units, \n",
    "                 num_hidden_units, \n",
    "                 batch_size, \n",
    "                 max_seq_len):\n",
    "        '''\n",
    "        inputs: in shape [batch_size, max_seq_len, input_size]\n",
    "        labels: in shape [batch_size]\n",
    "        '''\n",
    "\n",
    "        # ===>>> MultiRNNCell <<<===\n",
    "        multi_cells     = tf.contrib.rnn.MultiRNNCell([\n",
    "                            tf.contrib.rnn.BasicRNNCell(\n",
    "                                num_hidden_units) \\\n",
    "                            for _ in \\\n",
    "                            range(3) ])\n",
    "\n",
    "        sequence_length = [max_seq_len] * batch_size\n",
    "        last, states    = tf.nn.dynamic_rnn(\n",
    "                            multi_cells, \n",
    "                            inputs, \n",
    "                            sequence_length=sequence_length, \n",
    "                            dtype=tf.float32)\n",
    "        \n",
    "        # 여기서,\n",
    "        # last.shape: [batch_size, max_seq_len, num_hidden_units]\n",
    "        \n",
    "        #####################################################\n",
    "        # MultiRNNCell 을 쓰면 states값이 tensor 의 tuple 이 됨.\n",
    "        # states.shape : ([?, num_hidden_units],...)\n",
    "        #####################################################\n",
    "\n",
    "        print('last.shape', last.get_shape().as_list())\n",
    "        print('states', states)\n",
    "\n",
    "        # max_seq_len 축으로 0~27 까지 값 중에 \n",
    "        # 0~26 때의 출력 값은 사용하지 않음\n",
    "        rnn_output = last[:,max_seq_len-1,:] \n",
    "        # rnn_output shape: [batch_size, num_hidden_units]\n",
    "        print('rnn_output.shape', rnn_output.get_shape().as_list())\n",
    "\n",
    "        # 10 개의 output units 로 만들 \n",
    "        # FCN (fully-connected-network) 구성\n",
    "        # ==> shape: [batch_size, 10]\n",
    "        outputs    = tf.layers.dense(rnn_output, 10)\n",
    "        print('outputs.shape', outputs.get_shape().as_list())\n",
    "\n",
    "        # loss 함수\n",
    "        loss       = tf.losses.sparse_softmax_cross_entropy(\n",
    "                        labels, outputs)\n",
    "        optimize   = tf.train.AdamOptimizer(learning_rate=0.001). \\\n",
    "                        minimize(loss)\n",
    "\n",
    "        # accuracy\n",
    "        preds    = tf.argmax(outputs, axis=1)\n",
    "        errors   = tf.count_nonzero(labels - preds)\n",
    "        accuracy = 1.0 - tf.cast(errors,tf.float32) / \\\n",
    "                         tf.cast(tf.size(preds),tf.float32)\n",
    "\n",
    "        # 클래스 객체 외부에서 참고할 수 있도록 속성으로 저장\n",
    "        self.outputs        = outputs\n",
    "        self.loss           = loss\n",
    "        self.optimize       = optimize\n",
    "        self.accuracy       = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 그래프 초기화, Placeholders 정의, 그래프 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.shape [128, 28, 31]\n",
      "states (<tf.Tensor 'rnn/while/Exit_2:0' shape=(128, 31) dtype=float32>, <tf.Tensor 'rnn/while/Exit_3:0' shape=(128, 31) dtype=float32>, <tf.Tensor 'rnn/while/Exit_4:0' shape=(128, 31) dtype=float32>)\n",
      "rnn_output.shape [128, 31]\n",
      "outputs.shape [128, 10]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs_ = tf.placeholder(\n",
    "    tf.float32,\n",
    "    [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS],\n",
    "    name='inputs')\n",
    "labels_ = tf.placeholder(\n",
    "    tf.int64,\n",
    "    [BATCH_SIZE],\n",
    "    name='labels')\n",
    "\n",
    "model = MnistRnn(inputs_,\n",
    "                 labels_,\n",
    "                 INPUT_UNITS,\n",
    "                 NUM_HIDDEN_UNITS,\n",
    "                 BATCH_SIZE,\n",
    "                 MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션 초기화, 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter(\n",
    "    'logdir/train2',\n",
    "    graph=tf.get_default_graph())\n",
    "test_writer  = tf.summary.FileWriter(\n",
    "    'logdir/test2',\n",
    "    graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trn] ep 1, step 250, loss 1.210108, accu 0.117188, sec/iter 0.012381\n",
      "[tst] ep 1, step 500, accu 0.703125, sec/iter 0.004219\n",
      "[trn] ep 2, step 750, loss 0.489575, accu 0.695312, sec/iter 0.012057\n",
      "[tst] ep 2, step 1000, accu 0.773438, sec/iter 0.004077\n",
      "[trn] ep 3, step 1250, loss 0.345612, accu 0.796875, sec/iter 0.012037\n",
      "[tst] ep 3, step 1500, accu 0.828125, sec/iter 0.004014\n",
      "[trn] ep 4, step 1750, loss 0.288167, accu 0.796875, sec/iter 0.012005\n",
      "[tst] ep 4, step 2000, accu 0.851562, sec/iter 0.004372\n",
      "[trn] ep 5, step 2250, loss 0.251965, accu 0.812500, sec/iter 0.012174\n",
      "[tst] ep 5, step 2500, accu 0.867188, sec/iter 0.004039\n",
      "[trn] ep 6, step 2750, loss 0.224646, accu 0.843750, sec/iter 0.012116\n",
      "[tst] ep 6, step 3000, accu 0.875000, sec/iter 0.004018\n",
      "[trn] ep 7, step 3250, loss 0.207039, accu 0.843750, sec/iter 0.012183\n",
      "[tst] ep 7, step 3500, accu 0.875000, sec/iter 0.004154\n",
      "[trn] ep 8, step 3750, loss 0.182022, accu 0.882812, sec/iter 0.012206\n",
      "[tst] ep 8, step 4000, accu 0.890625, sec/iter 0.004082\n",
      "[trn] ep 9, step 4250, loss 0.177422, accu 0.875000, sec/iter 0.012283\n",
      "[tst] ep 9, step 4500, accu 0.890625, sec/iter 0.004715\n",
      "[trn] ep 10, step 4750, loss 0.166889, accu 0.882812, sec/iter 0.014717\n",
      "[tst] ep 10, step 5000, accu 0.914062, sec/iter 0.004244\n"
     ]
    }
   ],
   "source": [
    "train(inputs_, labels_, 10, train_writer, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !tensorboard --ip 0.0.0.0 --logdir logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고자료\n",
    "\n",
    "- Team AI Korea RNN Tutorials\n",
    "\n",
    "  - Part1 - http://aikorea.org/blog/rnn-tutorial-1/\n",
    "  - Part2 - http://aikorea.org/blog/rnn-tutorial-2/\n",
    "\n",
    "\n",
    "- WildML RNN Tutorial\n",
    "\n",
    "  - http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/\n",
    "\n",
    "\n",
    "- https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "\n",
    "- Tensorflow rnn_cell\n",
    "\n",
    "  - http://devdocs.io/tensorflow~python/tf/nn/rnn_cell\n",
    "\n",
    "\n",
    "- Tensorflow RNN Constructions\n",
    "\n",
    "  - https://www.tensorflow.org/api_guides/python/nn#Recurrent_Neural_Networks\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
